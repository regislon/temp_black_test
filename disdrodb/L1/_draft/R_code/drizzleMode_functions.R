source("library/latex_functions.R")

constructClasses = function(min, max, res, dp=2) {
    ## Construct drop-size classes.
    ##
    ## Args:
    ##   min, max: Minimum and maximum ranges for drops [mm].
    ##   res: Resolution for each class [mm].
    ##   dp: Round to this many decimal places (default: 2).
    ##
    ## Returns: data.frame with min and max per class.

    classes = data.frame(min=round(seq(min, max-res, by=res), dp))
    classes$max = round(classes$min + res, dp)
    return(classes)
}

defaultDVDClasses = function() {
    ## Returns default 2DVD drop-size classes for
    ## drizzle mode work.
    return(constructClasses(min=0, max=10, res=0.25))
}

defaultMPSClasses = function() {
    ## Returns default MPS drop-size classes for
    ## drizzle mode work.
    return(constructClasses(min=0.1, max=3.1, res=0.05))
}

processDVD = function(drops, res, dsdCols, start, classes,
    byCols=c("altitude", "longitude", "latitude")) {
    ## Process the 2DVD drops into DSDs for a certain time resolution.
    ##
    ## Args:
    ##   drops: 2DVD per-drop data.
    ##   res: Time resolution [s].
    ##   dsdCols: Columns for classes.
    ##   start: Start time to use.
    ##   classes: drop size classes (min/max in mm) to use.
    ##   byCols: Columns to keep.
    ##
    ## Returns: data.table with DSDs per time step, zero DSDs removed.

    dsds = drops[, data.table(resample2DVDdrops(DVDdropData=.SD,
        start=start, timeRes=res, diamRight=FALSE,
        diamClasses=classes, station=unique(station),
        performNonPhysFilter=FALSE)), by=byCols]

    ## Remove zero DSDs.
    dsds[, precipCode := NULL]
    dsds[, sum := rowSums(.SD), .SDcols=dsdCols]
    dsds = dsds[sum != 0]
    dsds[, sum := NULL]

    dsds = addClasses(dat=dsds, classes=classes)
    return(dsds)
}

processMPS = function(drops, res, dsdCols, start, classes,
    seaTemp, humidity,
    byCols=c("station", "altitude", "latitude", "longitude")) {
    ## Process the MPS drops into DSDs for a certain time resolution.
    ##
    ## Args:
    ##   drops: MPS per-drop data.
    ##   res: Time resolution [s].
    ##   dsdCols: Columns for classes (1-59).
    ##   start: Start time to use.
    ##   byCols: Columns that group the data (to keep).
    ##
    ## Returns: data.table with DSDs per time step, zero DSDs removed.

    ## Expect altitude and latitude in drops table.
    stopifnot(!any(c("altitude", "latitude") %in% ls()))
    stopifnot(all(c("altitude", "latitude") %in% names(drops)))
    stopifnot(!any(c("seaTemp", "humidity") %in% names(drops)))

    dsds = drops[, MPSDSDs(dat=.SD, timeRes=res, start=start,
        altitude=altitude, latitude=latitude, seaTemp=seaTemp,
        humidity=humidity), by=byCols]

    ## We don't trust MPS' first two classes (pers comm Thurai), so
    ## remove these from the spectra.
    stopifnot(all(c("Bin.1", "Bin.2") %in% names(dsds)))
    dsds[, Bin.1 := NULL]
    dsds[, Bin.2 := NULL]
    setnames(dsds, paste("Bin.", seq(3,62), sep=""), dsdCols)

    ## Remove zero DSDs.
    dsds[, sum := rowSums(.SD), .SDcols=dsdCols]
    dsds = dsds[sum != 0]
    dsds[, sum := NULL]

    dsds = addClasses(dat=dsds, classes=classes)
    return(dsds)
}

addClasses = function(dat, classes) {
    ## Add class diameter and width information to a DSD table.
    ##
    ## Args:
    ##  dat: The data.table of DSD information.
    ##  classes: Class definitions, min/max in mm.
    ##
    ## Returns: The data.table with "diam1..N" and "width1..N" added.

    diams = rowMeans(classes)
    widths = apply(classes, 1, diff)

    for(i in seq(1, length(diams))) {
        dat[, (paste("diam", i, sep="")) := diams[i]]
        dat[, (paste("width", i, sep="")) := widths[i]]
    }

    return(dat)
}

addMoments = function(dat, moments, dsdCols, diamCols, widthCols) {
    ## Add moments to a data.table of DSDs.
    ##
    ## Args:
    ##   dat: Data.table of DSDs.
    ##   moments: Moment order(s) to add.
    ##   dsdCols: Columns containing DSDs in mm-1 m-3.
    ##   diamCols: Columns containing class centre diameters in mm.
    ##   widthCols: Columns containing class widths in mm.
    ##
    ## Returns: the data from with moment_{x} added for each x in moments.

    dat = copy(dat)
    stopifnot(all(c(dsdCols, diamCols, widthCols) %in% names(dat)))

    for(i in moments) {
        momentName = paste("moment_", i, sep="")
        dat[, (momentName) := DSDMoment(dsd=.SD, n=i, dsdCols=dsdCols,
                               diamCols=diamCols, widthCols=widthCols)]
    }

    return(dat)
}

prettyNamesPlot = function(dat) {
    ## Make a column "varname" that contains variable names in
    ## expression format.
    ##
    ## Args:
    ##   dat: The data to use, must contain "variable".
    ##
    ## Returns: data.table with "varname" added.

    dat = copy(dat)
    stopifnot(!(c("momentNum", "varname") %in% names(dat)))
    stopifnot("variable" %in% names(dat))

    dat[, momentNum := str_match(variable, "moment_([0-9]*)")[,2]]
    dat[substr(variable, 1, 6) == "moment",
        varname := paste("Moment~", momentNum, "~group('[',mm^",
                    momentNum, "~m^{-3},']')", sep="")]
    dat[variable == "moment_0",
        varname := paste("Moment~0~group('[',m^{-3},']')", sep="")]
    dat[variable == "moment_1",
        varname := paste("Moment~1~group('[',mm~m^{-3},']')", sep="")]
    dat[variable == "R", varname := "italic(R)~group('[',mm~h^{-1},']')"]
    dat[variable == "Dm", varname := "italic(D[m])~group('[',mm,']')"]
    dat[, momentNum := NULL]

    ## Set variable order for plotting.
    dat[, varname :=
        factor(varname,
               levels=c(
                   paste("Moment~0~group('[',m^{-3},']')", sep=""),
                   paste("Moment~1~group('[',mm~m^{-3},']')", sep=""),
                   paste("Moment~", seq(2,7), "~group('[',mm^", seq(2,7), "~m^{-3},']')", sep=""),
                   "italic(D[m])~group('[',mm,']')",
                   "italic(R)~group('[',mm~h^{-1},']')"))]

    return(dat)
}

prettyNamesLaTeX = function(dat) {
    ## Make a column "varname" that contains variable names in
    ## latex maths format.
    ##
    ## Args:
    ##   dat: The data to use, must contain "variable".
    ##
    ## Returns: data.table with "varname" added.

    dat = copy(dat)
    stopifnot(!(c("momentNum", "varname") %in% names(dat)))
    stopifnot("variable" %in% names(dat))

    dat[, momentNum := str_match(variable, "moment_([0-9]*)")[,2]]
    dat[substr(variable, 1, 6) == "moment",
        varname := paste("Moment ", momentNum, " [mm$^{",
                    momentNum, "}$ m$^{-3}$]", sep="")]
    dat[variable == "moment_0",
        varname := paste("Moment 0 [m$^{-3}$]", sep="")]
    dat[variable == "moment_1",
        varname := paste("Moment 1 [mm m$^{-3}$]", sep="")]
    dat[variable == "R", varname := "$R$ [mm h$^{-1}$]"]
    dat[variable == "Dm", varname := "$D_m$ [mm]"]
    dat[, momentNum := NULL]
    return(dat)
}

changeTimeRes = function(dat, origRes, newRes, dsdCols, diamCols, widthCols, startTime) {
    ## Find mean DSDs for in a data set, assuming that
    ## missing time steps are zeros.
    ##
    ## Args:
    ##   dat: data.table with DSD data.
    ##   origRes: time resolution of dat [s].
    ##   newRes: new time resolution (multiple of origRes) [s].
    ##   dsdCols, diamCols, widthCols: Columns for DSDs [m-3 mm-1],
    ##                                 class widths [mm], and class
    ##                                 centres [mm].
    ##   startTime: first time step in sequence, so it can be a round number.
    ##
    ## Returns: daily aggregated DSDs.

    ## Ensure the origRes is correct.
    stopifnot(dat[, min(diff(POSIXtime))*60] == origRes)

    ## Ensure newRes is a multiple of origRes.
    stopifnot(newRes %% origRes == 0)

    ## Ensure startTime is less than the minimum time in the sequence.
    stopifnot(startTime < dat[, min(POSIXtime)])

    ## Don't change the original data.
    dat = copy(dat)

    ## Make sequence of days in UTC time.
    timeSeq = seq(startTime, dat[, max(POSIXtime)]+2*newRes, by=newRes)

    ## Get widths and diameters and make sure they are unique.
    widths = unique(dat[, widthCols, with=FALSE])
    diams = unique(dat[, diamCols, with=FALSE])
    stopifnot(nrow(widths) == 1)
    stopifnot(nrow(diams) == 1)

    ## Assign a new time to each DSD.
    dat[, resampledTime := as.character(cut(POSIXtime+newRes, timeSeq, right=TRUE))]

    ## Sum all DSDs in each new time.
    resampled = dat[, lapply(.SD, sum), by=resampledTime, .SDcols=dsdCols]

    ## Divide by the time steps we expect in each day, to get
    ## a mean DSD taking counting missing time steps as zeros.
    newResTimesteps = newRes/origRes
    resampled[, (dsdCols) := .SD/newResTimesteps, .SDcols=dsdCols]

    ## Re-add the widths and diams.
    stopifnot(length(widthCols) == length(diamCols))
    for(i in seq(1, length(widthCols))) {
        resampled[, (widthCols[i]) := as.numeric(widths)[i]]
        resampled[, (diamCols[i]) := as.numeric(diams)[i]]
    }

    ## Add POSIXtime as the non-inclusive end of the measurement
    ## period for each day.
    resampled[, POSIXtime := as.POSIXct(resampledTime, tz="UTC")]
    resampled[, resampledTime := NULL]
    return(resampled)
}

convertToDaily = function(dat, origRes, dsdCols, diamCols, widthCols) {
    ## Find mean DSDs for in a data set, assuming that
    ## missing time steps are zeros.
    ##
    ## Args:
    ##   dat: data.table with DSD data.
    ##   origRes: time resolution of dat [s].
    ##   newRes: new time resolution (multiple of origRes) [s].
    ##   dsdCols, diamCols, widthCols: Columns for DSDs [m-3 mm-1],
    ##                                 class widths [mm], and class
    ##                                 centres [mm].
    ##
    ## Returns: daily aggregated DSDs.

    ## Ensure the origRes is correct.
    stopifnot(dat[, min(diff(POSIXtime))*60] == origRes)

    ## Ensure newRes is a multiple of origRes.


    ## Make sequence of days in UTC time.
    minTime = dat[, strftime(min(POSIXtime), format="%Y-%m-%d", tz="UTC")]
    maxTime = dat[, strftime(max(POSIXtime)+3600*24, format="%Y-%m-%d", tz="UTC")]
    minTime = as.POSIXct(minTime, tz="UTC")
    maxTime = as.POSIXct(maxTime, tz="UTC")
    daySeq = seq(minTime, maxTime, by=3600*24)
    daySeq = as.POSIXct(daySeq, tz="UTC")

    ## Get widths and diameters and make sure they are unique.
    widths = unique(dat[, widthCols, with=FALSE])
    diams = unique(dat[, diamCols, with=FALSE])
    stopifnot(nrow(widths) == 1)
    stopifnot(nrow(diams) == 1)

    ## Assign a day to each DSD.
    dat[, day := as.character(cut(POSIXtime, daySeq, right=TRUE))]

    ## Sum all DSDs in each day.
    daily = dat[, lapply(.SD, sum), by=day, .SDcols=dsdCols]

    ## Divide by the time steps we expect in each day, to get
    ## a mean DSD taking counting missing time steps as zeros.
    dayTimesteps = 3600*24/origRes
    daily[, (dsdCols) := .SD/dayTimesteps, .SDcols=dsdCols]

    ## Re-add the widths and diams.
    stopifnot(length(widthCols) == length(diamCols))
    for(i in seq(1, length(widthCols))) {
        daily[, (widthCols[i]) := as.numeric(widths)[i]]
        daily[, (diamCols[i]) := as.numeric(diams)[i]]
    }

    ## Add POSIXtime as the non-inclusive end of the measurement
    ## period for each day.
    daily[, POSIXtime := as.POSIXct(day, tz="UTC")+3600*24]
    return(daily)
}

plotFittedGGByTime = function(dat, dsdCols, diamCols, widthCols,
    formatTimestep, i, j, mpsTo=1, extraTitleLine=NULL, ncol=4,
    xpos=8, printTitle=TRUE) {
    ## For each time (POSIXtime) in a data.table, plot the DSD and
    ## normalised model.
    ##
    ## Args:
    ##   dat: DSDs with fitted mu, c, plus N0_prime, Dm_prime.
    ##   dsdCols, diamCols, widthCols: Columns for DSDs [m-3 mm-1],
    ##                                 class widths [mm], and class
    ##                                 centres [mm].
    ##   formatTimeStep: A function that takes each time and makes
    ##                   a title display.
    ##   mpsTo: The point to which MPS drop classes are used [mm].
    ##   i, j: Moment orders used for the normalisation.
    ##   extraTitleLine: Any extra information to add to the title?
    ##   ncol: Number of columns in the output plot.
    ##   xpos: Position on x axis for right hand side of parameter text.
    ##
    ## Returns: ggplot object.

    ## Convert to long form for plotting.
    longDSDs = longFormDSDs(dat, dsdCols=dsdCols,
        diamCols=diamCols, widthCols=widthCols)[N > 0]

    stopifnot(!any(c("i", "j") %in% names(dat)))
    stopifnot(all(c("mu", "c", diamCols, widthCols, dsdCols,
                    "N0_prime", "Dm_prime") %in% names(dat)))
    recon = dat[, reconstructDSDs(dat=copy(.SD), i=i, j=j, c=c,
        mu=mu, diamCols=diamCols), by=POSIXtime]
    reconClasses = paste("reconClass", seq(1, length(diamCols)), sep="")
    recon = longFormDSDs(recon, reconClasses, diamCols, widthCols)
    recon = recon[N >= longDSDs[, min(N)]]

    params = dat[, list(x=xpos, y=c(1.5e2, 1.5e1, 1.5e4, 1.5e3),
        val=c(
            paste("mu==", round(unique(mu), 2)),
            paste("c==", round(unique(c), 2)),
            paste("log10(N[0]*minute)==", round(log10(unique(N0_prime)), 2)),
            paste("D[m]*minute==", round(unique(Dm_prime), 2)))),
        by=POSIXtime]

    longDSDs[, time := formatTimestep(POSIXtime)]
    params[, time := formatTimestep(POSIXtime)]
    recon[, time := formatTimestep(POSIXtime)]

    longDSDs[, inst := "2DVD"]
    longDSDs[D < mpsTo, inst := "MPS"]
    recon[, inst := "Fitted GG"]

    title = paste("DSDs and fitted GG models, i=", i, ", j=", j, sep="")
    if(!is.null(extraTitleLine)) {
        title = paste(title, "\n", extraTitleLine, sep="")
    }

    if(!printTitle)
        title = NULL

    plot = (ggplot(longDSDs, aes(x=D, y=N)) +
            geom_point(aes(shape=inst)) +
            geom_text(data=params, aes(x=x, y=y, label=val), size=3.5,
                      hjust="right", parse=TRUE) +
            geom_line(data=recon, aes(colour=inst)) +
            scale_colour_manual(name="", values="red") +
            facet_wrap(~time, ncol=ncol) +
            scale_y_continuous(trans="log10") +
            scale_x_continuous(limits=c(0,8.5)) +
            theme_bw(textSize) + theme(legend.pos="bottom") +
            scale_shape_manual(values=c(19, 18), name="") +
            labs(title=title, x="D [mm]",
                 y=parse(text="N(D)~group('[',mm^{-1}~m^{-3},']')")))
    return(plot)
}

formatThreeMinTS = function(POSIXtime) {
    ## Format times into a three-minute from and to string.
    ##
    ## Args:
    ##  POSIXtime: The times to format (POSIXct, UTC).
    ##
    ## Returns: strings with HH:MM - HH:MM.

    return(paste(strftime(POSIXtime-180, format="%H:%M", tz="UTC"),
                 strftime(POSIXtime, format="%H:%M", tz="UTC"), sep=" - "))
}

formatOneMinTS = function(POSIXtime) {
    ## Format times into a one-minute from and to string.
    ##
    ## Args:
    ##  POSIXtime: The times to format (POSIXct, UTC).
    ##
    ## Returns: strings with HH:MM - HH:MM.

    return(paste(strftime(POSIXtime-60, format="%H:%M", tz="UTC"),
                 strftime(POSIXtime, format="%H:%M", tz="UTC"), sep=" - "))
}

formatDailyTS = function(POSIXtime) {
    ## Format times into a "date" string.
    ##
    ## Args:
    ##  POSIXtime: The times to format (POSIXct, UTC), assumed the end
    ##  of the time period considered.
    ##
    ## Returns: string with YYYY-mm-dd for the start of the day in
    ## question.

    times = strftime(POSIXtime-(3600*24), format="%Y-%m-%d", tz="UTC")

    idx = which(POSIXtime == as.POSIXct("1-1-1 00:00", tz="UTC"))
    if(length(idx) > 0)
        times[idx] = "Global"

    return(times)
}

plotCombinedDSDs = function(comb, dvd, mps, resolutions, times,
    stationName, dsdCols_comb, diamCols_comb, widthCols_comb, dsdCols_dsd,
    diamCols_dsd, widthCols_dsd, dsdCols_mps, diamCols_mps,
    widthCols_mps) {
    ## Make facetted plots for example times and resolutions, showing
    ## MPS, 2DVD, and combined DSDs.
    ##
    ## Args:
    ##   comb: complete DSDs, by resolution.
    ##   dvd: incomplete DSDs from 2DVD, by resolution.
    ##   mps: MPS measurements, by resolution.
    ##   resolutions: list of resolutions to plot.
    ##   times: corresponding times at each resolution to plot.
    ##   stationName: station to select.
    ##   dsdCols_comb, diamCols_comb, widthCols_comb: Columns for
    ##           DSDs [m-3 mm-1], class widths [mm], and class
    ##           centres [mm] in comb.
    ##   dsdCols_dsd, diamCols_dsd, widthCols_dsd: Columns for
    ##           DSDs [m-3 mm-1], class widths [mm], and class
    ##           centres [mm] in dsd.
    ##   dsdCols_mps, diamCols_mps, widthCols_mps: Columns for
    ##           DSDs [m-3 mm-1], class widths [mm], and class
    ##           centres [mm] in mps data.
    ##
    ## Returns: void.

    toPlot = NULL
    titles = NULL
    for(i in seq(1, length(times))) {
        res = resolutions[i]
        time = as.POSIXct(times[i], tz="UTC")

        combdat = comb[[res]][POSIXtime == time & station == stationName]
        mpsdat = mps[[res]][POSIXtime == time & station == stationName]
        dvddat = dvd[[res]][POSIXtime == time & station == stationName]

        plotDat = plotForm(comb=combdat, dsd=dvddat, mps=mpsdat,
            dsdCols_comb=dsdCols_comb, diamCols_comb=diamCols_comb,
            widthCols_comb=widthCols_comb, dsdCols_dsd=dsdCols_dsd,
            diamCols_dsd=diamCols_dsd, widthCols_dsd=widthCols_dsd,
            dsdCols_mps=dsdCols_mps, diamCols_mps=diamCols_mps,
            widthCols_mps=widthCols_mps)

        seconds = convertTimeStringsToUnit(res, unit="secs")
        titleString = paste(strftime(time-seconds,
            format="'%Y-%m-%d %H:%M'", tz="UTC"), "~+~'", res,
            "'~(italic(R)==", combdat[, round(R, 2)], ")", sep="")
        titles = c(titles, titleString)
        plotDat[, title := titleString]

        toPlot = rbind(toPlot, plotDat)
    }

    toPlot[, title := factor(title, levels=titles)]

    print(ggplot(toPlot[set != "Combined"], aes(x=D, y=N)) +
          geom_point(aes(shape=set, colour=set), size=2) +
          geom_line(data=toPlot[set == "Combined"]) +
          facet_wrap(~title, labeller="label_parsed") +
          scale_x_continuous(trans="log10", limits=c(0.1, 10)) +
          scale_y_continuous(trans="log10", limits=c(1e-4, 1e6)) +
          scale_shape_manual(values=c(4, 23), name="Inst.") +
          scale_colour_manual(values=c("black", "red"), name="Inst.") +
          annotation_logticks(sides="b") +
          labs(x=parse(text="italic(D)~group('[',mm,']')"),
               y=parse(text="italic(N(D))~group('[',mm^{-1}~m^{-3},']')")))
}

plotForm = function(comb, mps, dsd, by="POSIXtime", dsdName="2DVD",
    dsdCols_comb, diamCols_comb, widthCols_comb, dsdCols_dsd,
    diamCols_dsd, widthCols_dsd, dsdCols_mps, diamCols_mps,
    widthCols_mps) {
    ## Convert combined and incomplete DSDs into long forms ready for
    ## plotting.
    ##
    ## Args:
    ##   comb: complete DSDs.
    ##   dsd: incomplete DSDs.
    ##   mps: MPS measurements.
    ##   dsdCols_comb, diamCols_comb, widthCols_comb: Columns for
    ##           DSDs [m-3 mm-1], class widths [mm], and class
    ##           centres [mm] in comb.
    ##   dsdCols_dsd, diamCols_dsd, widthCols_dsd: Columns for
    ##           DSDs [m-3 mm-1], class widths [mm], and class
    ##           centres [mm] in dsd.
    ##
    ## Returns: a data.table with diameter class centres D, class
    ## widths dD, concentrations N, "by", and "set" indicating the
    ## data source.

    longComb = longFormDSDs(comb, dsdCols=dsdCols_comb,
        diamCols=diamCols_comb, widthCols=widthCols_comb, by=by)[N > 0]
    longDSD = longFormDSDs(dsd, dsdCols=dsdCols_dsd,
        diamCols=diamCols_dsd, widthCols=widthCols_dsd, by=by)[N > 0]
    longMPS = longFormDSDs(mps, dsdCols=dsdCols_mps,
        diamCols=diamCols_mps, widthCols=widthCols_mps, by=by)[N > 0]

    longComb[, set := "Combined"]
    longDSD[, set := dsdName]
    longMPS[, set := "MPS"]

    res = rbindlist(list(longComb, longDSD, longMPS), use.names=FALSE)
    return(res)
}

plotDrizzleReconstruction = function(comb, dsd, recon, resolutions, times,
    dsdCols_comb, diamCols_comb, widthCols_comb,
    dsdCols_dsd, diamCols_dsd, widthCols_dsd,
    dsdCols_recon, diamCols_recon, widthCols_recon,
    minHx=1e-4, maxHx=1e7, linD=FALSE) {
    ## For each DSD in a data.table, plot the complete and incomplete
    ## DSDs and normalised model.
    ##
    ## Args:
    ##   comb: complete DSDs.
    ##   dsd: incomplete DSDs.
    ##   dsdCols_comb, diamCols_comb, widthCols_comb: Columns for DSDs [m-3 mm-1],
    ##           class widths [mm], and class  centres [mm] in comb.
    ##   dsdCols_recon, diamCols_recon, widthCols_recon: as above but for recon.
    ##   dsdCols_dsd, diamCols_dsd, widthCols_dsd: as above but for dsd.
    ##   mu, c: Generalised gamma model parameters to use.
    ##   minHx: The minimum reconstructed h(x) to plot (default: 1e-3).
    ##   linD: Display x-axis (D) in linear scale? (Default: FALSE).
    ##
    ## Returns: ggplot object.

    toPlot = NULL
    titles = NULL
    allStats = NULL
    allReconStats = NULL
    
    for(t in seq(1, length(times))) {
        res = resolutions[t]
        time = as.POSIXct(times[t], tz="UTC")

        combdat = comb[[res]][POSIXtime == time]
        dsddat = dsd[[res]][POSIXtime == time]
        recondat = recon[[res]][POSIXtime == time]

        ## Stop if multiple rows (ie multiple stations) are returned.
        stopifnot(nrow(combdat) == 1)
        stopifnot(nrow(dsddat) == 1)
        stopifnot(nrow(recondat) == 1)

        ## Transform to plottable (long) format.
        longComb = longFormDSDs(combdat, dsdCols=dsdCols_comb,
            diamCols=diamCols_comb, widthCols=widthCols_comb)[N > 0]
        longDSD = longFormDSDs(dsddat, dsdCols=dsdCols_dsd,
            diamCols=diamCols_dsd, widthCols=widthCols_dsd)[N > 0]
        longRecon = longFormDSDs(recondat, dsdCols=dsdCols_recon,
            diamCols=diamCols_recon, widthCols=widthCols_recon)[N > minHx]

        plotdat = rbindlist(list(
            data.table(longComb, set="Complete"),
            data.table(longDSD, set="Incomplete"),
            data.table(longRecon, set="Reconstructed")), use.names=TRUE)

        seconds = convertTimeStringsToUnit(res, unit="secs")
        title = paste(strftime(time-seconds, format="%Y-%m-%d %H:%M", tz="UTC"),
            " + ", res, "\n", combdat[,station], sep="")
        titles = c(titles, title)

        plotdat[, title := title]

        stats = data.table(title=title, combInfo=c(
                paste("italic(N[t])==", round(combdat[, moment_0], 0), "~m^{-3}", sep=""),
                paste("italic(R)==", round(combdat[, R], 2), "~mm~h^{-1}", sep=""),
                paste("italic(D[m])==", round(combdat[, Dm], 2), "~mm", sep=""),
                paste("italic(Z)==", round(combdat[, 10*log10(moment_6)], 2), "~dBZ", sep="")),
            line=c(1.05, 0.96, 0.85, 0.76))

        reconStats = data.table(title=title, combInfo=c(
                paste("italic(N[t])==", round(recondat[, moment_0], 0), "~m^{-3}", sep=""),
                paste("italic(R)==", round(recondat[, R], 2), "~mm~h^{-1}", sep=""),
                paste("italic(D[m])==", round(recondat[, Dm], 2), "~mm", sep=""),
                paste("italic(Z)==", round(recondat[, 10*log10(moment_6)], 2), "~dBZ", sep="")),
            line=c(0.4, 0.31, 0.2, 0.11))

        allStats = rbind(allStats, stats)
        allReconStats = rbind(allReconStats, reconStats)
        toPlot = rbind(toPlot, plotdat)
    }

    toPlot[, title := factor(title, levels=titles, ordered=TRUE)]
    allStats[, title := factor(title, levels=titles, ordered=TRUE)]
    allReconStats[, title := factor(title, levels=titles, ordered=TRUE)]

    allStats[, yRange := toPlot[, log10(max(N))-log10(min(N))]]
    allReconStats[, yRange := toPlot[, log10(max(N))-log10(min(N))]]

    allStats[, TR_x := toPlot[, max(D)]]
    allStats[, TR_y := toPlot[, 10^(log10(min(N)) + yRange*line)]]
    allReconStats[, BL_x := toPlot[, min(D)]]
    allReconStats[, BL_y := toPlot[, 10^(log10(min(N)) + yRange*line)]]

    if(toPlot[, min(N) < minHx | max(N) > maxHx])
        stop("Plot will crop y values.")

    plot = (ggplot(toPlot[set != "Reconstructed"], aes(x=D, y=N)) +
            geom_point(aes(shape=set, colour=set), size=2) +
            geom_line(data=toPlot[set == "Reconstructed"], size=0.8, colour="blue") +
            facet_wrap(~title) +
            scale_y_continuous(trans="log10", limits=c(minHx, maxHx)) +
            scale_shape_manual(values=c(4, 23), name="DSD type") +
            scale_colour_manual(values=c("black", "red"), name="DSD type") +
            labs(x=parse(text="italic(D)~group('[',mm,']')"),
                 y=parse(text="italic(N(D))~group('[',mm^{-1}~m^{-3},']')")))

    if(!linD) {
        plot = (plot +
                scale_x_continuous(trans="log10", limits=c(0.1, 10)) +
                annotation_logticks(sides="b") +
                geom_text(data=allStats, aes(x=TR_x, y=TR_y, label=combInfo),
                          parse=TRUE, size=5, hjust=1) +
                geom_text(data=allReconStats, aes(x=BL_x, y=BL_y, label=combInfo),
                          parse=TRUE, size=5, hjust=0, colour="blue"))
    }

    print(plot)
}

reconstructFromMoments = function(dat, i, j, mu, c, diams, widths,
    seaLevelTemp, seaLevelHumidity, idcols=c("POSIXtime", "station")) {
    ## Reconstruct DSDs and add moments and rain rate, for certain diameters.
    ##
    ## Args:
    ##   dat: data.table containing moment_i, moment_j (for i,j), altitude,
    ##        latitude, and idcols.
    ##   i, j: Moment orders i and j to use.
    ##   mu, c: Generalised gamma model parameters.
    ##   diams: Diameters to reconstruct for (must be a row from data.table).
    ##   widths: Class widths for each diameter (should be row from data.table).
    ##   seaLevelTemp: Assumed sea level temperature for R [deg. C].
    ##   idcols: Columns to keep from dat.
    ##
    ## Returns: Reconstructed DSDs with moments zero and seven, Dm, and R.

    stopifnot(all(c("altitude", "latitude") %in% names(dat)))
    stopifnot(paste("moment_", i, sep="") %in% names(dat))
    stopifnot(paste("moment_", j, sep="") %in% names(dat))

    ## Can't contain 'n'.
    stopifnot(!("n" %in% names(dat)))

    ## Get moments to use.
    dat[, ithMoment := .SD, .SDcols=paste("moment_", i, sep="")]
    dat[, jthMoment := .SD, .SDcols=paste("moment_", j, sep="")]

    recon = dat[, c(idcols, "ithMoment", "jthMoment", "altitude", "latitude"), with=FALSE]

    dsdCols = paste("reconClass", seq(1, length(diams)), sep="")
    diamCols = paste("diam", seq(1, length(diams)), sep="")
    widthCols = paste("width", seq(1, length(widths)), sep="")

    stopifnot(is.data.table(diams))
    stopifnot(is.data.table(widths))
    recon[, (diamCols) := diams]
    recon[, (widthCols) := widths]

    recon = reconstructDSDs(dat=recon, i=i, j=j, mu=mu, c=c, diamCols=diamCols)

    for(n in seq(0, 7)) {
        momentCol = paste("moment_", n, sep="")
        recon[, (momentCol) := DSDMoment(.SD, n=n, dsdCols=dsdCols,
                                diamCols=diamCols, widthCols=widthCols)]
    }

    classes = data.frame(min=t(diams-widths/2), max=t(diams+widths/2))
    recon[, Dm := moment_4 / moment_3]
    recon[, R := DSDRainrate(.SD, classes=classes, altitude=altitude,
                  latitude=latitude, seaLevelTemperature=seaLevelTemp,
                  seaLevelRelativeHumidity=seaLevelHumidity),
          by=c("altitude", "latitude"), .SDcols=dsdCols]

    return(recon)
}

compareVars = function(test, ref, idcols=c("POSIXtime","station")) {
    ## Test statistics against a reference.
    ##
    ## Args:
    ##  test: results to test (moments 0 to 7, R, Dm).
    ##  ref: Reference values for the same stats.
    ##  idcols: Columns to use as IDs for matching between sets.
    ##
    ## Returns: statistics table.

    ## Check columns exist.
    stopifnot(idcols %in% names(test))
    stopifnot(idcols %in% names(ref))
    stopifnot(!any(c("variable", "value") %in% names(test)))
    stopifnot(!any(c("variable", "value") %in% names(ref)))

    ## Variables to test, plus ID columns.
    cols = c(idcols, paste("moment_", seq(0,7), sep=""), "R", "Dm")

    test = melt(test[, cols, with=FALSE], id.vars=idcols, variable.factor=FALSE)
    ref = melt(ref[, cols, with=FALSE], id.vars=idcols, variable.factor=FALSE)
    setnames(test, "value", "test")
    setnames(ref, "value", "ref")

    setkeyv(test, c("variable", idcols))
    setkeyv(ref, c("variable", idcols))

    set = ref[test, nomatch=0]

    set[, diff := test - ref]
    set[, relDiff := diff / ref * 100]

    ## Difference stats over the whole set.
    stats = set[, list(
        bias = mean(diff),
        medRelBias = median(relDiff),
        meanRelBias = mean(relDiff),
        q10RelBias = quantile(relDiff, probs=0.10),
        q25RelBias = quantile(relDiff, probs=0.25),
        q75RelBias = quantile(relDiff, probs=0.75),
        q90RelBias = quantile(relDiff, probs=0.90),
        rmse = sqrt(mean(diff^2)),
        r2 = cor(ref, test)^2), by=variable]

    stats[, RBIQR := q75RelBias - q25RelBias, by=variable]
    return(list(comparisons=set, stats=stats))
}

plotModelPerformance = function(stats, by=NULL, legendName=NULL, dodgeWidth=0, legendRows=1,
    lineSize=0.6) {
    ## Make a plot showing medians and IQRs of relative bias from
    ## stats produced using compareVars.
    ##
    ## Args:
    ##   stats: stats from eg. compareVars().
    ##   by: Colour by this variable (default: none).
    ##   legendName: Name for the colour legend.
    ##   dodgeWidth: positions will be dodged up to this width (default: 0).
    ##   legendRows: Number of rows in the legend (default: 1).
    ##
    ## Returns: the plot.

    ## Do not change the original data.
    stats = copy(stats)

    ## Display "moment_X" as "MX".
    stats[, variable := factor(variable,
                         levels=c(paste("moment_", seq(0,7), sep=""), "R", "Dm"),
                         labels=c(paste("M[", seq(0,7), "]", sep=""), "R", "D[m]"))]

    aesth = aes(x=variable)
    if(!is.null(by))
       aesth = aes_string(x="variable", colour=by)

    plot = (ggplot(stats, aesth) +
            geom_hline(yintercept=0) +
            geom_point(aes(y=medRelBias), position=position_dodge(width=dodgeWidth),
                       shape=4, size=2, stroke=1) +
            geom_errorbar(aes(ymin=q25RelBias, ymax=q75RelBias),
                          width=0, size=lineSize,
                          position=position_dodge(width=dodgeWidth)) +
            scale_x_discrete(labels=parse(text=levels(stats$variable))) +
            scale_colour_discrete(name=legendName) +
            labs(x="Variable", y="RB [%]") +
            guides(colour=guide_legend(nrow=legendRows, byrow=TRUE)) +
            theme(legend.position="bottom"))
    return(plot)
}

printPerfTable = function(stats, cap, ref, ...) {
    ## Print results as a table.
    ##
    ## Args:
    ##   stats: data.table of statistics.
    ##   cap: Caption to use.
    ##   ref: Table reference for LaTeX.
    ##   ...: Extra arguments to printTab().
    ##
    ## Returns: void, prints table.

    stats = copy(stats)

    stats[variable == "R", variable := "$R$"]
    stats[variable == "Dm", variable := "$D_m$"]
    stats[substr(variable, 1, 6) == "moment",
          variable := paste("$M_", str_match(variable,
                       "moment_([0-9]*)")[,2], "$", sep="")]

    ## Round to required decimal places.
    stats[, r2 := round(r2, 2)]
    stats[, bias := round(bias, 1)]
    stats[, rmse := round(rmse, 1)]
    stats[, meanRelBias := round(meanRelBias, 2)]
    stats[, medRelBias := round(medRelBias, 2)]
    stats[, RBIQR := round(RBIQR, 0)]

    ## Set order.
    stats[, variable := factor(variable,
                levels = c(paste("$M_", seq(0,7), "$", sep=""),
                    "$D_m$", "$R$"))]

    ## Disable scientific notation.
    options(scipen=999)

    tab = tabular((Var=Factor(variable, texify=FALSE))~
        Heading()*identity*Justify(r)*
        (Heading("Bias")*bias+
         Heading("RMSE")*rmse+
         Heading("$\\overline{\\textrm{RB}}$")*meanRelBias+
         Heading("M.RB")*medRelBias+
         Heading("IQR.RB")*RBIQR+
         Heading("r${^2}$")*r2), data=stats)

    ## Restore default.
    options(scipen=0)

    printTab(tab, caption=cap, ref=ref, ...)
}

printCompTable = function(stats, newName, extName, cap, ref, by="set",
    tabCols=c(extName, newName, "Difference"), ...) {
    ## Print a comparison table show existing results, new results, and
    ## difference.
    ##
    ## Args:
    ##   stats: data.table of statistics, must contains cols (below) and
    ##          a "by" column for the sets.
    ##   newName: The value of the by column for the new stats.
    ##   extName: The value of the by column for the existing stats.
    ##   cap: Caption to use.
    ##   ref: Table reference for LaTeX.
    ##   by: The "by" column name (default: "set").
    ##   ...: Extra arguments to printTab().
    ##
    ## Returns: void, prints table.

    cols = c("bias", "meanRelBias", "medRelBias", "RBIQR", "rmse", "r2")

    stats = copy(stats)
    stopifnot(!("by" %in% names(stats)))

    setnames(stats, by, "by")

    ext = data.table(stats[by == extName], set=extName)
    new = data.table(stats[by == newName], set=newName)

    setkey(ext, variable)
    setkey(new, variable)

    extForDiffs = ext[, list(bias=abs(bias),
        meanRelBias=abs(meanRelBias),
        medRelBias=abs(medRelBias),
        rmse=abs(rmse),
        RBIQR=abs(RBIQR),
        r2=(1-r2))]
    newForDiffs = new[, list(bias=abs(bias),
        meanRelBias=abs(meanRelBias),
        medRelBias=abs(medRelBias),
        rmse=abs(rmse),
        RBIQR=abs(RBIQR),
        r2=(1-r2))]

    ext = ext[, c("variable", "set", cols), with=FALSE]
    new = new[, c("variable", "set", cols), with=FALSE]

    ## Negative diffs show an improvement by "new" over "ext".
    diffs = data.table(variable=ext[,variable], newForDiffs - extForDiffs)
    diffs[, set := "Difference"]

    stats = rbindlist(list(ext, new, diffs), use.names=TRUE)
    stats[variable == "R", variable := "$R$"]
    stats[variable == "Dm", variable := "$D_m$"]
    stats[substr(variable, 1, 6) == "moment",
          variable := paste("$M_", str_match(variable,
                       "moment_([0-9]*)")[,2], "$", sep="")]
    stats[, set := factor(set, levels=c(extName, newName, "Difference"))]

    stats = stats[set %in% tabCols]
    stats[, set := factor(set, levels=tabCols)]

    ## Round to required decimal places.
    stats[, r2 := round(r2, 2)]
    stats[, bias := round(bias, 1)]
    stats[, rmse := round(rmse, 1)]
    stats[, meanRelBias := round(meanRelBias, 2)]
    stats[, medRelBias := round(medRelBias, 2)]
    stats[, RBIQR := round(RBIQR, 0)]

    momentDiffs = stats[set == "Difference" &
        variable %in% paste("$M_", seq(0,7), "$", sep="")]
    bulkDiffs = stats[set == "Difference" &
        variable %in% c("$R$", "$D_m$")]

    ## Collect some performance figures.
    figs=list(bestImpMedRB=round(momentDiffs[which.min(medRelBias), medRelBias], 0),
        bestImpMedRBVariable=momentDiffs[which.min(medRelBias), variable],
        worstImpMedRB=round(momentDiffs[which.max(medRelBias), medRelBias], 0),
        worstImpMedRBVariable=momentDiffs[which.max(medRelBias), variable],
        RImp=round(bulkDiffs[variable == "$R$", medRelBias], 0),
        DmImp=round(bulkDiffs[variable == "$D_m$", medRelBias], 0))

    ## Disable scientific notation.
    options(scipen=999)

    stats[, variable := factor(variable,
                levels = c(paste("$M_", seq(0,7), "$", sep=""),
                    "$D_m$", "$R$"))]

    tab = tabular((Var=Factor(variable, texify=FALSE))~Heading()*Factor(set)*
        Heading()*identity*Justify(r)*
        (Heading("Bias")*bias+
         Heading("RMSE")*rmse+
         Heading("$\\overline{\\textrm{RB}}$")*meanRelBias+
         Heading("M.RB")*medRelBias+
         Heading("IQR.RB")*RBIQR+
         Heading("r${^2}$")*r2), data=stats)

    ## Restore default.
    options(scipen=0)

    printTab(tab, caption=cap, ref=ref, ...)
    return(figs)
}

addBulkVars = function(dat, momentOrders, dsdCols, diamCols, widthCols, seaTemp, seaHumidity) {
    ## Add moments and bulk variables to a DSD data set.
    ##
    ## Args:
    ##   dat: DSD data.
    ##   momentOrders: moment orders to add.
    ##   dsdCols, diamCols, widthCols: Columns for DSDs [m-3 mm-1],
    ##                                 class widths [mm], and class
    ##                                 centres [mm].
    ##   seaTemp: Sea level tempurature [deg C].
    ##   seaHumidity: Sea level relative humidity.
    ##
    ## Returns: same data.table with moment_*, R, Dm added.

    ## Calculate moments for both sets.
    dat = addMoments(dat=dat, moments=momentOrders, dsdCols=dsdCols,
        diamCols=diamCols, widthCols=widthCols)

    ## Add rain rates.
    stopifnot(c("altitude", "latitude") %in% names(dat))
    diams = unique(dat[, diamCols, with=FALSE])
    widths = unique(dat[, widthCols, with=FALSE])
    stopifnot(nrow(diams) == 1)
    stopifnot(nrow(widths) == 1)
    classes = data.frame(min=t(diams-widths/2), max=t(diams+widths/2))
    dat[, R := DSDRainrate(spectra=.SD, classes=classes, altitude=altitude,
                latitude=latitude, seaLevelTemperature=seaTemp,
                seaLevelRelativeHumidity=seaHumidity),
        .SDcols=dsdCols, by=c("latitude", "altitude")]

    ## Calculate Dm.
    dat[, Dm := moment_4/moment_3]

    return(dat)
}

resampleDataset = function(dat, origRes, resampleRes, moments, startTime,
    dsdCols, diamCols, widthCols, seaTemp, seaHumidity,
    minR=0.1, byCols=c("station", "altitude", "latitude", "longitude")) {
    ## Resample a dataset into multiple new time resolutions, assuming
    ## missing values are zeros.
    ##
    ## Args:
    ##   dat: The data.table of DSD data to resample.
    ##   origRes: Time resolution of 'dat'.
    ##   resampleRes: New time resolutions, specified as strings ("5 min" etc).
    ##   moments: Moments to compute?
    ##   startTime: Start time for resampling.
    ##   dsdCols, diamCols, widthCols: Columns for DSDs [m-3 mm-1],
    ##                                 class widths [mm], and class
    ##                                 centres [mm].
    ##   seaTemp: Sea level tempurature [deg C].
    ##   seaHumidity: Sea level relative humidity.
    ##   byCols: Columns to process by - essentially columns to keep.
    ##
    ## Returns: a list of data.tables, resampled, with moment_*, R, Dm added,
    ##          with the list names as the name of each time resolution.

    stopifnot(all(byCols %in% names(dat)))
    stopifnot(all(c(dsdCols, diamCols, widthCols) %in% names(dat)))
    resampledList = list()
    for(i in seq(1, length(resampleRes))) {
        resStr = resampleRes[i]
        newRes = convertTimeStringsToUnit(resStr, unit="secs")

        resampled = dat[, changeTimeRes(dat=.SD, origRes=origRes,
            newRes=newRes, startTime=startTime,
            dsdCols=dsdCols, widthCols=widthCols,
            diamCols=diamCols), by=byCols]

        ## Add bulk vars.
        resampled = addBulkVars(dat=resampled, momentOrders=moments,
            dsdCols=dsdCols, diamCols=diamCols, widthCols=widthCols,
            seaTemp=seaTemp, seaHumidity=seaHumidity)

        resampledList[[resStr]] = copy(resampled)
    }

    return(resampledList)
}

tryGammaFunctions = function(dsds, i, j, dsdCols, diamCols, widthCols,
    startMu, startC, plotXClassSize, seaTemp, seaLevelHumidity,
    maxTries=4, by="station") {
    ## Fit a generalised gamma model to normalised DSD data in various
    ## different ways (different weight factors p and x class widths).
    ##
    ## Args:
    ##   dsds: (Unnormalised) DSDs to fit to.
    ##   i, j: Moment orders to use in normalisation.
    ##   dsdCols, diamCols, widthCols: Columns for DSDs [m-3 mm-1],
    ##                                 class widths [mm], and class
    ##                                 centres [mm].
    ##   startMu, startC: initial values for mu and c in the fit.
    ##   plotXClassSize: Show plot with x in classes with this width.
    ##   seaTemp: Sea-level temperature to test DSDs with.
    ##   seaLevelHumidity: Sea-level relative humidity for R.
    ##   by: Extra columns (POSIXtime already included) to treat separately.
    ##
    ## Returns: parameter table for each fit combinations.

    ## Do not change original data.
    dsds = copy(dsds)

    ## Combinations of weight p and class size dx to test.
    testCombs = data.table(
        p=c(0, 0, 0, 0, 1, 4, 0, 1),
        dx=c(0.02, 0.05, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2),
        avgCol=c("median", "median", "median", "median", "median", "median", "mean", "mean"))

    ## Find normalised DSDs.
    normDSDs = dsds[, callNormalisedDSD(.SD, dsdCols=dsdCols,
        widthCols=widthCols, diamCols=diamCols, i=i, j=j), by=by]

    ## Fit simple GG models to each individual DSD.
    indiv = fitSimpleGG(normDSDs=normDSDs, i=i, j=j,
        startMu=startMu, startC=startC, by=c("POSIXtime", by),
        maxTries=maxTries)
    GGParams = data.table(fit="Median parameters",
        exp="Median parameters",
        mu=indiv[, round(median(mu), 2)], c=indiv[, round(median(c), 2)],
        fit_p=NA, fit_dx=NA, fit_avg=NA)

    ## Fit GG models to average (mean/median) normalised DSDs.
    for(t in seq(1, nrow(testCombs))) {
        p = testCombs[t, p]
        dx = testCombs[t, dx]
        avgCol = testCombs[t, avgCol]

        fitRes = fitAvgGG(normDSDs=normDSDs, i=i, j=j, weightFactor=p,
            xClassSize=dx, avgCol=avgCol, startMu=startMu, startC=startC,
            maxTries=maxTries)

        ## Round parameters to two decimal places.
        fitRes[, mu := round(mu, 2)]
        fitRes[, c := round(c, 2)]
        fitRes[, fit_p := p]
        fitRes[, fit_dx := dx]
        fitRes[, fit_avg := avgCol]

        GGParams = rbind(GGParams, data.table(
            fit=paste("Fit to ", avgCol, " ($p=", p, "$, $dx=", dx, "$)", sep=""),
            exp=paste("Fit to ", avgCol, " (p=", p, ", dx=", dx, ")", sep=""),
            fitRes))

        rm(list=c("fitRes", "p", "dx", "avgCol"))
    }

    ## Plot all the fits over the normalised DSDs.
    fitPlot = plotNormFits(normDSDs=normDSDs, GGParams=GGParams,
        plotXClassSize=plotXClassSize, moment_i=i, moment_j=j)

    ## Model performances.
    perf = modelPerformances(dsds=dsds, i=i, j=j, GGParams=GGParams,
        diamCols=diamCols, widthCols=widthCols, seaTemp=seaTemp,
        seaLevelHumidity=seaLevelHumidity)

    return(list(params=GGParams, fitPlot=fitPlot, indivFits=indiv,
                perfPlot=perf$plot, perfStats=perf$stats))
}

modelPerformances = function(dsds, i, j, GGParams, diamCols, widthCols,
    seaTemp, seaLevelHumidity, idcols=c("POSIXtime","station")) {
    ## Calculate performances for a set of different models.
    ##
    ## Args:
    ##   dsds: (Unnormalised) DSDs.
    ##   i, j: Moment orders to use in normalisation.
    ##   GGParams: list of parameters with exp, fit, mu, and c.
    ##   dsdCols, diamCols, widthCols: Columns for DSDs [m-3 mm-1],
    ##                                 class widths [mm], and class
    ##                                 centres [mm].
    ##   seaTemp: Sea-level temperature to test DSD Rs with.
    ##   seaLevelHumidity: Sea-level relative humidity for R.
    ##   idcols: ID columns to keep.
    ##
    ## Returns: a list with a plot of relative bias distributions and
    ## statistics on performances for each model.

    reconDiams = unique(dsds[, diamCols, with=FALSE])
    reconWidths = unique(dsds[, widthCols, with=FALSE])
    stopifnot(nrow(reconDiams) == 1)
    stopifnot(nrow(reconWidths) == 1)

    modelPerf = NULL
    for(n in seq(1, nrow(GGParams))) {
        recon = reconstructFromMoments(dat=dsds, i=i, j=j,
            mu=GGParams[n, mu], c=GGParams[n, c],
            diams=reconDiams, widths=reconWidths,
            seaLevelTemp=seaTemp,
            seaLevelHumidity=seaLevelHumidity,
            idcols=idcols)
        reconStats = compareVars(test=recon, ref=dsds)$stats

        reconStats[, fit := GGParams[n, fit]]
        reconStats[, exp := GGParams[n, exp]]
        modelPerf = rbind(modelPerf, reconStats)

        rm(list=c("recon", "reconStats"))
    }

    perfPlot = plotModelPerformance(stats=modelPerf,
        by="exp", legendRows=5, legendName="Fit",
        dodgeWidth=0.7)

    return(list(plot=perfPlot, stats=modelPerf))
}

reconstructAllDSDs = function(dsds, i, j, params, resolutions, diamCols,
    widthCols, diams, widths, seaLevelTemp, seaLevelHumidity, ...) {
    ## Reconstruct DSDs from moments, in a list of different resolutions.
    ##
    ## Args:
    ##   dsds: A list of (incomplete) dsds per resolution.
    ##   i, j: Moment orders to use for reconstruction.
    ##   params: Parameters per resolution (c and mu).
    ##   resolutions: List of resolution names (names in lists).
    ##   diamCols, widthCols: Diameter columns in dsds[[]]
    ##   diams, widths: (Class-centre) diameters and class widths to
    ##                  reconstruct [mm].
    ##   seaLevelTemp, seaLevelHumidity: Temp [deg. C] and rel. humidity
    ##                                   at sea level, for R calculation.
    ##  ...: Optional extra arguments to reconstructFromMoments().
    ##
    ## Returns: list of reconstructed DSDs per resolution.

    stopifnot(nrow(diams) == 1)
    stopifnot(nrow(widths) == 1)

    recon = list()
    for(resName in resolutions) {
        recon[[resName]] = reconstructFromMoments(dat=dsds[[resName]], i=i, j=j,
                 mu=params[res == resName, mu],
                 c=params[res == resName, c],
                 diams=diams, widths=widths,
                 seaLevelTemp=seaLevelTemp,
                 seaLevelHumidity=seaLevelHumidity, ...)
    }

    return(recon)
}

plotNormFits = function(normDSDs, GGParams, plotXClassSize, moment_i, moment_j) {
    ## Make a plot of normalised DSDs with fitted models on top.
    ##
    ## Args:
    ##   normDSDs: Normalised DSDs to plot.
    ##   GGParams: Parameters for each model to plot.
    ##   plotXClassSize: Show plot with x in classes with this width.
    ##
    ## Returns: ggplot object.

    ## Quantiles to plot.
    fitQuantiles = normQuantiles(dat=normDSDs, xClassSize=plotXClassSize)
    fitQuantiles = fitQuantiles[, sum := rowSums(.SD),
        .SDcols=c("q01", "q10", "q25", "median", "q75", "q90","q99")]
    fitQuantiles = fitQuantiles[sum != 0]
    fitQuantiles[, sum := NULL]

    ## Subset quantiles to plot for display purposes.
    xSeq = seq(fitQuantiles[, min(x)], fitQuantiles[, max(x)], by=plotXClassSize*3)
    fitQuantiles = fitQuantiles[round(x, 2) %in% round(xSeq, 2)]

    fitData = copy(normDSDs[hx > 0])
    xvals = seq(0.02, fitData[, max(x)], by=0.02)

    fitLines = GGParams[, list(x=xvals,
        hx=generalisedGamma(x=xvals, mu=mu, c=c, i=moment_i, j=moment_j)), by=exp]
    fitLines = fitLines[hx > fitData[, min(hx)]]

    alphaVal = 0.35
    fitPlot = (ggplot(fitData) +
               geom_bin2d(aes(x=x, y=hx), bins=100, alpha=alphaVal) +
               geom_errorbar(data=fitQuantiles, width=plotXClassSize, size=0.6,
                             aes(x=x, ymin=q25, ymax=q75), stat="identity") +
               geom_point(data=fitQuantiles, aes(x=x, y=median), shape=4, size=3, stroke=1) +
               geom_line(data=fitLines, aes(color=exp, x=x, y=hx), size=1.2) +
               scale_y_continuous(trans="log10") +
               scale_fill_gradientn(colours=topo.colors(10),
                                    breaks=c(1, 10, 100),
                                    name="Number of points", trans="log10") +
               scale_colour_discrete(name="Fit method") +
               guides(fill=guide_legend(override.aes=list(alpha=alphaVal))) +
               labs(x=parse(text="italic(x)"), y=parse(text="italic(h(x))")))
    return(fitPlot)
}

fitSimpleGG = function(normDSDs, i, j, startMu, startC, by="POSIXtime", ...) {
    ## Fit a simple generalised gamma model to each in a set of DSDs.
    ##
    ## Args:
    ##   normDSDs: normalised DSDs.
    ##   i: ith moment order to use in normalisation.
    ##   j: jth moment order to use in normalisation.
    ##   dsdCols: Col names in 'dsds' containing DSD N(D) values [mm-1 m-3].
    ##   diamCols: Col names in 'dsds' containing diameter class centres [mm].
    ##   widthCols: Col names in 'dsds' containing diameter class widths [mm].
    ##   ...: Optional extra arguments to simpleGGfito().
    ##
    ## Returns: a data.table with POSIXtime, and fitted mu and c values.

    ## Check columns.
    normDSDs = copy(normDSDs)
    stopifnot(by %in% names(normDSDs))
    stopifnot(!any(c("i", "j") %in% names(normDSDs)))

    ## Set up columns for i and j.
    normDSDs[, ("i") := i]
    normDSDs[, ("j") := j]
    normDSDs[, weight := 1]

    ## Do the fit for each time.
    fits = normDSDs[, simpleGGfit(.SD, startMu=startMu, startC=startC, ...), by=by]

    return(fits)
}

normQuantiles = function(dat, xClassSize=0.1) {
    ## Break normalised DSDs into classes of double-normalised diameter x and
    ## find quantiles per class.
    ##
    ## Args:
    ##   dat: Data containing at least hx and x.
    ##   xClassSize: class size for normalised diameter x [-] (default: 0.2).
    ##
    ## Returns: data.table with x (middle of x class), quantiles, and
    ##          np the number of points in each class.

    stopifnot(all(c("hx", "x") %in% names(dat)))

    ## Find median normalised DSD.
    xClasses = seq(0, max(dat$x)+xClassSize, by=xClassSize)
    dat[, xClass := cut(x, xClasses, labels=FALSE)]
    dat = dat[, list(
        q01=quantile(hx, probs=0.01),
        q10=quantile(hx, probs=0.10),
        q25=quantile(hx, probs=0.25),
        median=median(hx),
        mean=mean(hx),
        q75=quantile(hx, probs=0.75),
        q90=quantile(hx, probs=0.90),
        q99=quantile(hx, probs=0.99),
        np=length(hx)), by=xClass]
    dat[, x := xClasses[xClass]+xClassSize/2]
    dat[, xClass := NULL]

    return(dat)
}

fitAvgGG = function(normDSDs, i, j, weightFactor=1, xClassSize=0.1, avgCol="median", ...) {
    ## Fit a simple generalised gamma model to the average (mean or median) normalised DSD.
    ##
    ## Args:
    ##   normDSDs: Normalised DSDs.
    ##   i: ith moment order to use in normalisation.
    ##   j: jth moment order to use in normalisation.
    ##   dsdCols: Col names in 'dsds' containing DSD N(D) values [mm-1 m-3].
    ##   diamCols: Col names in 'dsds' containing diameter class centres [mm].
    ##   widthCols: Col names in 'dsds' containing diameter class widths [mm].
    ##   weightFactor: Weight by number of points in each class to this power (default: 1).
    ##   avgCol: Column in result from normQuantiles to fit on (default: median).
    ##   ...: Optional extra arguments to simpleGGfit().
    ##
    ## Returns: a data.table with POSIXtime, and fitted mu and c values.

    ## Check columns.
    stopifnot(!any(c("i", "j") %in% names(normDSDs)))

    ## Find averaged normalised DSD.
    fitData = normQuantiles(normDSDs, xClassSize=xClassSize)
    fitData[, weight := np^weightFactor]
    setnames(fitData, avgCol, "hx")

    ## Set up columns for i and j.
    fitData[, ("i") := i]
    fitData[, ("j") := j]

    ## Do the fit for each time.
    fits = simpleGGfit(dat=fitData, ...)

    return(fits)
}

## fitGG.quants = function(normDSDs, i, j, weightFactor=1, xClassSize=0.1, avgCol="median", ...) {
##     ## Fit a simple generalised gamma model to the average (mean or median) normalised DSD.
##     ##
##     ## Args:
##     ##   normDSDs: Normalised DSDs.
##     ##   i: ith moment order to use in normalisation.
##     ##   j: jth moment order to use in normalisation.
##     ##   dsdCols: Col names in 'dsds' containing DSD N(D) values [mm-1 m-3].
##     ##   diamCols: Col names in 'dsds' containing diameter class centres [mm].
##     ##   widthCols: Col names in 'dsds' containing diameter class widths [mm].
##     ##   weightFactor: Weight by number of points in each class to this power (default: 1).
##     ##   avgCol: Column in result from normQuantiles to fit on (default: median).
##     ##   ...: Optional extra arguments to simpleGGfit().
##     ##
##     ## Returns: a data.table with POSIXtime, and fitted mu and c values.




##     ## ssdFit -
##     set.seed(1953)
##     r = rnorm(500)
##     hist(r, breaks = "FD", probability = TRUE,
##          col = "steelblue", border = "white")
##     ## ssdFit -
##     param = ssdFit(r)
##     ## dssd -
##     u = seq(min(r), max(r), len = 301)
##     v = dssd(u, param)
##     lines(u, v, col = "orange", lwd = 2)
##     ## Check columns.
##     stopifnot(!any(c("i", "j") %in% names(normDSDs)))

##     ## Find averaged normalised DSD.
##     fitData = normQuantiles(normDSDs, xClassSize=xClassSize)

##     fitData = fitData[, list(hx=median, x)]

##     ggplot(fitData, aes(x=x, y=hx)) + geom_line() + geom_point() +
##         scale_y_log10()



##     fitData[, weight := np^weightFactor]
##     setnames(fitData, avgCol, "hx")

##     ## Set up columns for i and j.
##     fitData[, ("i") := i]
##     fitData[, ("j") := j]

##     ## Do the fit for each time.
##     fits = simpleGGfit(dat=fitData, ...)

##     return(fits)
## }

wideFormDSDs = function(dat) {
    ## Take DSDs in long format, as returned by longFormDSDs(), and
    ## return wide format.
    ##
    ## Args:
    ##   dat: The DSDs with columns POSIXtime, D, dD, and N.
    ##        as given by longFormDSDs().
    ##
    ## Returns: wide form DSDs.

    stopifnot(all(c("POSIXtime", "D", "N", "dD") %in% names(dat)))
    setkey(dat, POSIXtime, D)
    diams = dat[, unique(D)]
    wide = dcast(dat, POSIXtime~D, value.var="N")
    setnames(wide, as.character(diams), paste("class", seq(1, length(diams)), sep=""))

    for(i in seq(1, length(diams))) {
        wide[, (paste("diam", i, sep="")) := diams[i]]
        wide[, (paste("width", i, sep="")) := dat[D == diams[i], unique(dD)]]
    }

    return(wide)
}

longFormDSDs = function(dat, dsdCols, diamCols, widthCols, by="POSIXtime") {
    ## Take DSDs in wide format, with diameter class information, as
    ## used by the normalisation routines. Return the same data in
    ## long format ready to plot.
    ##
    ## Args:
    ##   dat: DSD data in wide form.
    ##   dsdCols: Col names in 'dsds' containing DSD N(D) values [mm-1 m-3].
    ##   diamCols: Col names in 'dsds' containing diameter class centres [mm].
    ##   widthCols: Col names in 'dsds' containing diameter class widths [mm].
    ##
    ## Return: a data.table with columns N [mm-1 m-3], D [mm], and dD [mm] for
    ## concentration, class centre, and class width respectively.

    ## Check columns.
    stopifnot(all(c(dsdCols, diamCols, widthCols, by) %in% names(dat)))
    stopifnot(!("keyval" %in% names(dat)))

    dat = copy(dat)
    setnames(dat, by, "keyval")

    ret = NULL
    for(line in dat[, unique(keyval)]) {
        dsd = as.numeric(dat[keyval == line, dsdCols, with=FALSE])
        diams = as.numeric(dat[keyval == line, diamCols, with=FALSE])
        widths = as.numeric(dat[keyval == line, widthCols, with=FALSE])

        dt = data.table(D=diams, N=dsd, dD=widths, keyval=line)
        if(by == "POSIXtime")
            dt[, keyval := as.POSIXct(keyval, tz="UTC", origin="1970-1-1")]

        ret = rbind(ret, dt)
    }

    setnames(dat, "keyval", by)
    setnames(ret, "keyval", by)
    return(ret)
}

fitGGtoDSDs = function(dsds, i, j, dsdCols, widthCols, diamCols, startMu, startC, ...) {
    ## For each DSD in a set, calculate some statistics (ith and jth moment,
    ## N0', Dm') and fit a simple generalised gamma model.
    ##
    ## Args:
    ##   dsds: data.table of DSDs to work on.
    ##   i, j: Moment orders to use for double-moment normalisation.
    ##   dsdCols: Col names in 'dsds' containing DSD N(D) values [mm-1 m-3].
    ##   diamCols: Col names in 'dsds' containing diameter class centres [mm].
    ##   widthCols: Col names in 'dsds' containing diameter class widths [mm].
    ##   startMu, startC: starting parameters for the fit (mu and c).
    ##   ...: Optional extra arguments to fitSimpleGG().
    ##
    ## Returns: a data.table with N0_prime, Dm_prime, ithMoment, jthMoment, c,
    ##          and mu added for each DSD.

    ## Copy the object so as to not change the original.
    dsds = copy(dsds)

    if(any(c("i", "j") %in% names(dsds))) {
        stop("i and j can not be column names in dsds.")
    }

    ## Calculate the ith and jth moments for each DSD.
    dsds[, ithMoment := DSDMoment(dsd=.SD, n=i, dsdCols=dsdCols,
                         widthCols=widthCols, diamCols=diamCols)]
    dsds[, jthMoment := DSDMoment(dsd=.SD, n=j, dsdCols=dsdCols,
                         widthCols=widthCols, diamCols=diamCols)]

    ## Calculate N0' and Dm'.
    dsds[, N0_prime := ithMoment^((j+1)/(j-i)) * jthMoment^((i+1)/(i-j))]
    dsds[, Dm_prime := (jthMoment/ithMoment)^(1/(j-i))]

    ## Find the normalised DSD.
    normDSDs = dsds[, callNormalisedDSD(.SD, dsdCols=dsdCols,
        widthCols=widthCols, diamCols=diamCols, i=i, j=j)]

    ## Fit a simple generalised gamma model to each combined DSD.
    fits = fitSimpleGG(normDSDs=normDSDs, i=i, j=j, startMu=startMu, startC=startC, ...)

    ## Add fit results back into the DSD data.table.
    setkey(fits, POSIXtime)
    setkey(dsds, POSIXtime)
    dsds[, mu := fits[dsds, mu]]
    dsds[, c := fits[dsds, c]]

    return(dsds)
}

simpleGGfit = function(dat, startMu, startC, maxTries=4, minMu=-Inf, maxMu=Inf, maxC=Inf) {
    ## Perform a simple least-squares fit of the generalised gamma function
    ## to find the optimum values for c and mu. The fit is made in log-log
    ## space.
    ##
    ## Args:
    ##   dat: The data to fit to; must contain:
    ##        hx - output of h(x) normalised DSD function.
    ##        x - corresponding normalised diameter x input.
    ##        i - ith moment order to use.
    ##        j - jth moment order to use.
    ##        weight - weight for this data point in the fit.
    ##   startMu: Starting value for mu (increased by 1 up to maxTries times
    ##            until fit is found).
    ##   startC: Starting value for c.
    ##   minMu, maxMu: Range for fitted values of mu.
    ##   maxC: Maximum fitted c (minimum is zero).
    ##   maxTries: Maximum number of fits to try, increaseing startMu
    ##             by one each time.
    ##
    ## Returns: a data table with fitted values for c and mu.

    stopifnot(all(c("hx", "x", "i", "j", "weight") %in% names(dat)))
    dat = dat[!is.na(x) & hx > 0]
    try = 0

    while(try+1 <= maxTries) {
        fit = tryCatch({nlsLM(formula="log(hx)~log(generalisedGamma(x, mu, c, i, j))",
            data=dat, start=list(mu=startMu+try, c=startC),
            lower=c(minMu, 0), upper=c(maxMu, maxC),
            control=nls.lm.control(maxiter=200), weights=weight)},
            error = function(cond) {
                return("error") })

        if(class(fit) == "nls") break
        try = try + 1
    }

    if(class(fit) != "nls") {
        stop(paste("Simple GG fit failed after", try, "attempts",
                   "with different starting values."))
    }

    return(data.table(t(coef(fit))))
}

addDrizzleStations = function(dat) {
    ## Add station information to a data.table.
    ##
    ## Args:
    ##  dat: The data.table containing "station".
    ##
    ## Returns: The same data.table modified in place to include
    ## latitude, longitude, altitude.

    ## Station information from Thurai_JAMC_2017:
    ## Greeley: 40.32735698 deg. N, 104.60939448 deg. W; 1.4 km MSL.
    ## Huntsville: 34.723 333 38N, 86.641 944 48W; 212 m MSL.

    stopifnot("station" %in% names(dat))
    stopifnot(!any(c("latitude", "longitude", "altitude") %in% names(dat)))

    stations = rbindlist(list(
        data.table(name="Greeley", lat=40.32735698, lon=-104.60939448, altitude=1400),
        data.table(name="Huntsville", lat=34.72333338, lon=-86.64194448, altitude=212)),
        use.names=TRUE)

    setkey(stations, name)
    setkey(dat, station)
    dat[, altitude := stations[dat, altitude]]
    dat[, latitude := stations[dat, lat]]
    dat[, longitude := stations[dat, lon]]

    stopifnot(!any(dat[, is.na(altitude)]))
    stopifnot(!any(dat[, is.na(latitude)]))
    stopifnot(!any(dat[, is.na(longitude)]))

    return(dat)
}

GGpdf = function(x, c, lambda, mu) {
    ## Return generalised gamma pdf values.
    ##
    ## Args:
    ##  x: Values for which to find probabilities.
    ##  c, lambda, mu: Generalised gamma model parameters.
    ##
    ## Returns: the probability for each x.

    stopifnot(lambda > 0)
    stopifnot(c > 0)
    stopifnot(mu > 0)

    res = (c*lambda)/gamma(mu) * (lambda*x)^(c*mu - 1) * exp(-(lambda * x)^c)
    return(res)
}

writeNumber = function(x, capitalise=FALSE) {
    ## Write a number in words if less than 10, or leave as-is if not.
    require(english)
    require(Hmisc)

    words = as.character(english(x, UK=TRUE))
    if(capitalise)
        words = capitalize(words)

    res = rep(NA, length(x))
    res[x >= 10] = as.character(x[x >= 10])
    res[x < 10] = words[x < 10]
    stopifnot(!any(is.na(res)))
    return(res)
}

compareOverlap = function(mps, dvd, overlapDVDClasses,
    dvdClasses, mpsClasses, classCol="class") {
    ## Compare concentrations in overlapping classes.
    ##
    ## Args:
    ##  mps: MPS data.
    ##  dvd: DVD data.
    ##  overlapDVDClasses: the 2DVD class numbers to compare, in which
    ##                     we expect overlap.
    ##  dvdClasses, mpsClasses: min/max diameters [mm] for MPS and
    ##                          2DVD classes.
    ##  classCol: The name of class columns (classCol + number).
    ##
    ## Returns: list with stats (data.table with comparison results by
    ## class and station. Results with _mps use the MPS as the
    ## reference, those with _dvd use 2DVD as the reference. Bias uses
    ## the 2DVD as the reference) and comp (overlap comparisons for
    ## each station, POSIXtime, and class).

    mpsWidth = unique(round(mpsClasses$max-mpsClasses$min, 3))
    dvdWidth = unique(round(dvdClasses$max - dvdClasses$min, 3))
    numInComp = as.integer(dvdWidth/mpsWidth)

    mpsClassNums = seq(1, nrow(mpsClasses))

    overlap = NULL
    for(class in overlapDVDClasses) {
        dvdClass = dvdClasses[class,]
        dvdSD = paste(classCol, class, sep="")

        mpsSD = paste(classCol,
            mpsClassNums[which(mpsClasses$min >= dvdClass$min &
                               mpsClasses$max <= dvdClass$max)], sep="")

        ## Check the right number of MPS classes are included.
        stopifnot(length(mpsSD) == numInComp)

        dvdRes = dvd[, .SD, .SDcols=dvdSD, by=c("POSIXtime", "station")]
        setnames(dvdRes, dvdSD, "dvd")

        ## Note that here we could also do
        ##   mpsConc [mm-1 m-3] * mpsWidth [mm] = mpsConc_perm3 [m-3]
        ##   sum(mpsConc_perm3) / dvdWidth = res [mm-1 m-3]
        ## which is equivalent to taking the mean in mm-1 m-3 as long as
        ## dvdWidth/mpsWidth == number in the mean.
        mpsRes = mps[, list(mps=rowMeans(.SD)),
            .SDcols=mpsSD, by=c("POSIXtime", "station")]

        setkey(dvdRes, POSIXtime, station)
        setkey(mpsRes, POSIXtime, station)

        overlap = rbind(overlap, data.table(dvdRes[mpsRes, nomatch=0], dvdClass=class))
    }

    ## Select only times for which both instruments recorded drops in compared classes.
    overlap = overlap[dvd > 0 & mps > 0]

    ## Use MPS as reference:
    overlap[, diff_mps := dvd-mps]
    overlap[, reldiff_mps := (diff_mps) / mps * 100]

    ## Use 2DVD as reference:
    overlap[, diff_dvd := mps-dvd]
    overlap[, reldiff_dvd := (diff_dvd) / dvd * 100]

    ## Compute statistics by 2DVD class.
    stats = overlap[, list(bias=mean(diff_dvd),
        rmse=sqrt(mean(diff_dvd^2)),
        meanRB_mps=mean(reldiff_mps),
        medRB_mps=median(reldiff_mps),
        RBIQR_mps=IQR(reldiff_mps),
        q25_mps=quantile(reldiff_mps, probs=0.25),
        q75_mps=quantile(reldiff_mps, probs=0.75),
        meanRB_dvd=mean(reldiff_dvd),
        medRB_dvd=median(reldiff_dvd),
        RBIQR_dvd=IQR(reldiff_dvd),
        q25_dvd=quantile(reldiff_dvd, probs=0.25),
        q75_dvd=quantile(reldiff_dvd, probs=0.75),
        r2=cor(mps, dvd)^2),
        by=c("dvdClass", "station")]

    ## Return statistics and comparison results for scatterplot.
    return(list(stats=stats, comp=overlap))
}

densityMax = function(x) {
    ## Determine the mode of a distribution of values.
    ##
    ## Args:
    ##   x: The array of values.
    ##
    ## Returns: The most

    den = density(x)
    return(den$x[which.max(den$y)])
}

compareParsPluv = function(parsDat, pluvDat, seaTemp, minR, maxR=Inf,
    classCols=paste("class", seq(1,32), sep=""),
    stations=stationsDefinition_2013(), timeRes=300,
    pluvioStations=pluvioStationsDefinition(),
    classes=get.classD()) {
    ## Compare Parsivel to Pluvio data.
    ##
    ## Args:
    ##   parsDat: Parsivel data.
    ##   pluvDat: Pluvio data.
    ##   seaTemp: Sea-level temperature for R.
    ##   minR: Minimum R to accept in Parsivel data.
    ##   classCols: Class columns for DSDs in Parsivel data.
    ##   stations: Parsivel station defs.
    ##   pluvioStations: Pluvio station defs.
    ##
    ## Returns: list with mean and median DSD from Parsivel,
    ##          comparisons and comparison statistics.

    ## Process parsivel data.
    parsDat = addRainStats(spectra=parsDat, timestepSeconds=timeRes,
        seaLevelTemperature=seaTemp, radar=FALSE, stations=stations,
        classes=classes, dsdColNames=classCols)
    parsDat = parsDat[!containedNonZeroStatus & ## Filter out Parsivel errors.
        R >= 0.1 &             ## Filter out too-low-R.
        solidPrecipProp == 0 & ## Filter out steps with too many solid detections.
        parsivelR > 0.025]     ## Filter when parsivel R was very close to zero.

    ## Find mean and median DSDs.
    meanDSD = data.table(D=rowMeans(classes),
        N=as.numeric(parsDat[, lapply(.SD, mean), .SDcols=classCols]),
        avgMethod="Mean DSD")
    medianDSD = data.table(D=rowMeans(classes),
        N=as.numeric(parsDat[, lapply(.SD, median), .SDcols=classCols]),
        avgMethod="Median DSD")

    ## Combine Pars and pluvio measurements to compare.
    pluvDat = pluvDat[
        R >= minR &    ## Filter out R too low.
        R < maxR]     ## Filter out R too high.

    compPluv = pluvDat[, list(POSIXtime, pluvio=station, pluvioR=R, pluvioAmount=amount)]
    compPars = parsDat[, list(POSIXtime, station, parsR=R, parsAmount=amount)]

    stationKey = data.table(closestPluvio(s=stations, p=pluvioStations))

    ## Special cases for HYMEX data.
    stationKey[station == "Pradel Grainage", pluvio := "Pradel Grainage"]
    stationKey[station == "Pradel Grainage", pluvioDistance := 0]
    stationKey[station == "Pradel Grainage v2", pluvio := "Pradel Grainage"]
    stationKey[station == "Pradel Grainage v2", pluvioDistance := 0]

    ## Set pluvio station for each parsivel station.
    setkey(stationKey, station)
    compPars[, pluvio := stationKey[compPars, pluvio]]
    compPars[, pluvioDistance := stationKey[compPars, pluvioDistance]]

    ## Combine data sets.
    setkey(compPluv, POSIXtime, pluvio)
    setkey(compPars, POSIXtime, pluvio)
    comp = compPluv[compPars, nomatch=0]

    ## Do the comparison.
    comp[, diff := parsR - pluvioR]
    comp[, relDiff := diff / pluvioR * 100]
    comp[is.infinite(relDiff), relDiff := NA]

    stats = comp[, list(bias=mean(diff),
        RMSE=sqrt(mean(diff^2)),
        meanRB=mean(relDiff, na.rm=TRUE),
        medRB=median(relDiff, na.rm=TRUE),
        RB25=quantile(relDiff, probs=0.25, na.rm=TRUE),
        RB75=quantile(relDiff, probs=0.75, na.rm=TRUE),
        RBIQR=IQR(relDiff, na.rm=TRUE),
        r2=cor(pluvioR, parsR)^2,
        pluvAmount=sum(pluvioAmount),
        parsAmount=sum(parsAmount)), by=c("station", "pluvio", "pluvioDistance")]

    stats[, amountRelBias := (parsAmount - pluvAmount) / pluvAmount * 100]
    return(list(meanDSD=meanDSD, medianDSD=medianDSD, comp=comp, stats=stats))
}

plotHyMeXNormComparison = function(combDat1, parsDat1, combDat2, parsDat2,
    res1, res2, i, j, combDSDCols, combDiamCols, combWidthCols, xClassSize,
    xlims=c(0.02,2.5), classes=get.classD()) {
    ## Plot a comparison of HyMeX and combined normalised DSDs, showing medians
    ## and IQRs of h(x) by classes of x.
    ##
    ## Args:
    ##  combDat1,2: Combined 2DVD+MPS data (at two resolutions).
    ##  parsDat1,2: Parsivel data (at two resolutions).
    ##  res1,2: Resolution names.
    ##  i, j: Moment orders to use for normalisation.
    ##  combDSDCols/combDiamCols/combWidthCols: DSD, diameter, and width
    ##                                          column names for combDat.
    ##  xClassSize: class size for x to use in the plot.
    ##  xlims: Limits for x axis.
    ##  classes: Classes for Parsivel data.
    ##
    ## Returns: plot showing median and IQR of h(x) for each set.

    widths = apply(classes, 1, diff)
    diams = rowMeans(classes)
    for(class in seq(1,nrow(classes))) {
        diamName = paste("diam", class, sep="")
        widthName = paste("width", class, sep="")
        parsDat1[, (diamName) := diams[class]]
        parsDat1[, (widthName) := widths[class]]
        parsDat2[, (diamName) := diams[class]]
        parsDat2[, (widthName) := widths[class]]
    }
    parsDSDCols = paste("class", seq(1, nrow(classes)), sep="")
    parsDiamCols = paste("diam", seq(1, nrow(classes)), sep="")
    parsWidthCols = paste("width", seq(1, nrow(classes)), sep="")
    stopifnot(all(parsDSDCols %in% names(parsDat1)))
    stopifnot(all(parsDSDCols %in% names(parsDat2)))
    stopifnot(all(c(combDSDCols, combWidthCols, combDiamCols) %in% names(combDat1)))
    stopifnot(all(c(combDSDCols, combWidthCols, combDiamCols) %in% names(combDat2)))

    ## Resolution 1.
    parsQuantiles1 = hxQuantiles(dat=parsDat1, dsdCols=parsDSDCols,
        widthCols=parsWidthCols, diamCols=parsDiamCols, i=i, j=j,
        xClassSize=xClassSize)
    combQuantiles1 = hxQuantiles(dat=combDat1, dsdCols=combDSDCols,
        widthCols=combWidthCols, diamCols=combDiamCols, i=i, j=j,
        xClassSize=xClassSize)

    ## Resolution 2.
    parsQuantiles2 = hxQuantiles(dat=parsDat2, dsdCols=parsDSDCols,
        widthCols=parsWidthCols, diamCols=parsDiamCols, i=i, j=j,
        xClassSize=xClassSize)
    combQuantiles2 = hxQuantiles(dat=combDat2, dsdCols=combDSDCols,
        widthCols=combWidthCols, diamCols=combDiamCols, i=i, j=j,
        xClassSize=xClassSize)

    plotDat = rbindlist(list(
        data.table(parsQuantiles1, set="Parsivel", res=res1),
        data.table(combQuantiles1, set="2DVD+MPS", res=res1),
        data.table(parsQuantiles2, set="Parsivel", res=res2),
        data.table(combQuantiles2, set="2DVD+MPS", res=res2)))
    plotDat[, res := factor(res, levels=c(res1, res2))]

    xLim = max(c(plotDat[q25 != 0, max(x)],
        plotDat[median != 0, max(x)],
        plotDat[q75 != 0, max(x)]))
    stopifnot(plotDat[x > xLim, q25 == 0])
    stopifnot(plotDat[x > xLim, q75 == 0])
    stopifnot(plotDat[x > xLim, median == 0])
    plotDat = plotDat[x <= xLim]
    
    plot = (ggplot(plotDat, aes(x=x)) +
            geom_line(aes(y=median, colour=set)) +
            geom_ribbon(aes(ymin=q25, ymax=q75, fill=set, colour=set), alpha=0.3) +
            scale_y_log10() +
            scale_x_continuous() +
            labs(x=parse(text="italic(x)"), y=parse(text="italic(h(x))")) +
            scale_colour_discrete(name="Dataset") +
            scale_fill_discrete(name="Dataset") +
            facet_wrap(~res, ncol=2))
    
    return(plot)
}

hxQuantiles = function(dat, dsdCols, widthCols, diamCols, i, j,
    by="station", xClassSize=0.05) {
    ## Find quantiles of h(x) per class of x.
    ##
    ## Args:
    ##  dat: Unnormalised DSDs.
    ##  dsdCols, widthCols, diamCols: Column names for DSDs, widths, diameters in dat.
    ##  i,j: DSD moment orders to use for normalisation.
    ##  by: separate by this variable (default: station).
    ##  xClassSize: the class size in x to use.
    ##
    ## Returns: quantiles of h(x) by class of x.

    normDSDs = dat[, callNormalisedDSD(.SD, dsdCols=dsdCols,
        widthCols=widthCols, diamCols=diamCols, i=i, j=j), by=by]
    normDSDs = normDSDs[!is.na(hx)]
    quants = normQuantiles(dat=normDSDs, xClassSize=xClassSize)
    return(quants)
}

combineAndResample = function(mps, dsd, mpsClasses, dsdClasses, mpsCols,
    dsdCols, mpsTo, momentOrders, seaTemp, seaHumidity, resampleRes, startTime,
    origRes=60, origResName="1 min") {

    comb_res = combineDSDsWithMPS(mps=mps, dsd=dsd, mpsClasses=mpsClasses,
        dsdClasses=dsdClasses, mpsCols=mpsCols, dsdCols=dsdCols, mpsTo=mpsTo)

    combDSDCols = names(comb_res)[str_which(names(comb_res), pattern="class.*")]
    combDiamCols = names(comb_res)[str_which(names(comb_res), pattern="diam.*")]
    combWidthCols = names(comb_res)[str_which(names(comb_res), pattern="width.*")]

    ## Add bulk variables.
    comb_res = addBulkVars(dat=comb_res, momentOrders=momentOrders,
        dsdCols=combDSDCols, diamCols=combDiamCols, widthCols=combWidthCols,
        seaTemp=seaTemp, seaHumidity=seaHumidity)

    ## Resample to various time resolutions.
    comb = resampleDataset(dat=comb_res, origRes=origRes, resampleRes=resampleRes,
        moments=momentOrders, startTime=startTime, dsdCols=combDSDCols,
        widthCols=combWidthCols, diamCols=combDiamCols, seaTemp=seaTemp,
        seaHumidity=seaHumidity)
    comb[[origResName]] = copy(comb_res)

    ## Remove combined DSDs that have drops in only one class, since
    ## we can not fit a model to DSDs with only one point.
    numRemoved_1class = list()
    percRemoved_1class = list()
    numRemoved_R = list()
    percRemoved_R = list()

    for(res in c(origResName, resampleRes)) {
        comb[[res]][, numCols := rowSums(.SD > 0), .SDcols=combDSDCols]
        stopifnot(comb[[res]][, all(numCols >= 1)])
        numRemoved_1class[[res]] = nrow(comb[[res]][numCols <= 1])
        combLines = nrow(comb[[res]])
        percRemoved_1class[[res]] = round(numRemoved_1class[[res]] / combLines * 100, 1)
        comb[[res]] = comb[[res]][numCols > 1]
        comb[[res]][, numCols := NULL]

        ## Remove DSDs with too low rain rate.
        numRemoved_R[[res]] = nrow(comb[[res]][R < minR])
        percRemoved_R[[res]] = round(numRemoved_R[[res]] / combLines * 100, 1)
        comb[[res]] = comb[[res]][R >= minR]
        rm(list=c("combLines"))
    }

    return(list(comb=comb, numRemoved_1class=numRemoved_1class,
                percRemoved_1class=percRemoved_1class,
                numRemoved_R=numRemoved_R, percRemoved_R=percRemoved_R,
                combDSDCols=combDSDCols, combDiamCols=combDiamCols,
                combWidthCols=combWidthCols))
}

chooseBestModels = function(GGfits, resolutions, max_r2_diff=0.2, maxRBDiff=15)  {
    ## From a list of GG fits, choose the best fit.
    ##
    ## Args:
    ##   GGfits: results of tryGammaFunctions().
    ##   resolutions: List of resolution names.
    ##   max_r2_diff: Maximum difference to allow between best overall model worst 
    ##                r2 and best model in in terms of r2's r2.
    ##   maxRBDiff: Maximum diff to allow between best overall model's worst RB 
    ##              and the model chosen by using maximum RB's RB.
    ##
    ## Returns: best parameters for each time resolution.
    
    furthestFromZero = function(x) {
        maxidx = which.max(abs(x))
        return(x[maxidx])
    }
    
    bestParams = NULL
    for(res in resolutions) {
        perf = GGfits[[res]]$perfStats
        
        bestModel_medBias = perf[, list(
            stat=max(abs(medRelBias)),
            worstStat=furthestFromZero(medRelBias),
            meanRB=mean(abs(medRelBias)),
            worst_r2=min(r2),
            var=variable[which.max(abs(medRelBias))]), by=fit][which.min(abs(meanRB))]
        
        bestModel_maxBias = perf[, list(
            stat=max(abs(medRelBias)),
            worstStat=furthestFromZero(medRelBias),
            meanRB=mean(abs(medRelBias)),
            worst_r2=min(r2),
            var=variable[which.max(abs(medRelBias))]), by=fit][which.min(stat)]

        bestModel_maxBias = perf[, list(
            stat=max(abs(medRelBias)),
            worstStat=furthestFromZero(medRelBias),
            meanRB=mean(abs(medRelBias)),
            worst_r2=min(r2),
            var=variable[which.max(abs(medRelBias))]), by=fit][which.min(stat)]
        
        bestModel_r2 = perf[, list(
            worst_r2=min(r2),
            worst_r2_var=variable[which.min(r2)]), by=fit][which.max(worst_r2)]
        
        ## Check no more than max_r2 difference between worst r2 of least-biased
        ## model, and the worst r2 of best-r2 model.
        stopifnot(abs(bestModel_medBias$worst_r2 -
                      bestModel_r2$worst_r2) < max_r2_diff)
        
        ## Check no more than 15% between worst medRB in model chosen using mean RB and
        ## model chosen using best "maximum" RB.
        stopifnot(abs(bestModel_medBias[, stat] - bestModel_maxBias[, stat]) < maxRBDiff)
        
        bestParams = rbind(bestParams, GGfits[[res]]$params[fit == bestModel_medBias$fit,
            list(res=res, fitMethod=fit, mu, c, fit_p, fit_dx, fit_avg,
                 worstMedRB=round(bestModel_medBias$worstStat, 0),
                 variable=bestModel_medBias$var)])
    }
       
    return(bestParams)
}

processHyMeXComps = function(inDir, rawFile1, rawFile2, corrFile1,
    corrFile2, pluvFile, hymexSeaTemp, hymexHumidity,
    hymexTimeRes, hymexMinR, D, dD, gamma_mu, gamma_c,
    moment_i, moment_j, hymexMaxR=Inf) {
    ## Do comparisons between HyMeX pluvios and parsivels.
    ##
    ## Args:
    ##   rawFiles, corrFiles: P1 and P2 Rdata files for raw and corrected data.
    ##   pluvFile: Pluvio data file.
    ##   hymexSeaTemp: Sea temperature to use.
    ##   hymexHumidity: Humidity to use.
    ##   hymexTimeRes: Time resolution [s].
    ##   hymexMinR: Minimum R to count.
    ##   D, dD: drop classes to reconstruct.
    ##   gamma_mu, gamma_c: Gen. gamma model parameters for recon.
    ##   moment_i, moment_j: Moment orders for recon.
    ##
    ## Returns: comparison stats for raw, corrected, and reconstructed data
    ##          sets.

    ## Raw files for P1 and P2.
    raw1File = paste(inDir, rawFile1, sep="/")
    raw2File = paste(inDir, rawFile2, sep="/")

    ## Previous correction files for P1 and P2.
    corr1File = paste(inDir, corrFile1, sep="/")
    corr2File = paste(inDir, corrFile2, sep="/")

    ## Pluvio data.
    pluvDat = rbind(get(pluv1 <- load(paste(inDir, pluvFile, sep="/"))))

    ## Load raw data.
    rawDat = rbind(
        data.table(get(raw1 <- load(raw1File))),
        data.table(get(raw2 <- load(raw2File))))[!is.na(class3)]

    ## Load previous correction data.
    corrDat = rbind(
        data.table(get(corr1 <- load(corr1File))),
        data.table(get(corr2 <- load(corr2File))))[!is.na(class3)]

    ## Parsivel v2 data has errroneous drops in classes 1 and 2, remove these.
    rawDat[!is.na(class1), class1 := 0]
    rawDat[!is.na(class2), class2 := 0]
    corrDat[!is.na(class1), class1 := 0]
    corrDat[!is.na(class2), class2 := 0]

    ## Subset to SOP times.
    rawDat = rawDat[POSIXtime >= as.POSIXct("2013-09-01", tz="UTC") &
        POSIXtime <= as.POSIXct("2013-11-30", tz="UTC")]
    corrDat = corrDat[POSIXtime >= as.POSIXct("2013-09-01", tz="UTC") &
        POSIXtime <= as.POSIXct("2013-11-30", tz="UTC")]
    pluvDat = pluvDat[POSIXtime >= as.POSIXct("2013-09-01", tz="UTC") &
        POSIXtime <= as.POSIXct("2013-11-30", tz="UTC")]

    ## Remove stations that are too far away or had timing issues.
    rawDat = rawDat[!(station %in% c("Montbrun", "Villeneuve-de-Berg",
        "Villeneuve-de-Berg 2", "Pradel-Vignes"))]
    corrDat = corrDat[!(station %in% c("Montbrun", "Villeneuve-de-Berg",
        "Villeneuve-de-Berg 2", "Pradel-Vignes"))]

    ## Station info.
    stations = combinedSOPstations()
    stations[name == "Pradel-Grainage-v2", name := "Pradel Grainage v2"]

    ## Pluvio info.
    pluvioStations = pluvioStationsDefinition()
    rawComp = compareParsPluv(parsDat=rawDat,
        pluvDat=pluvDat, seaTemp=hymexSeaTemp, minR=hymexMinR,
        maxR=hymexMaxR, classCols=paste("class", seq(1,32), sep=""),
        stations=stations, timeRes=hymexTimeRes,
        pluvioStations=pluvioStations)

    corrComp = compareParsPluv(parsDat=corrDat,
        pluvDat=pluvDat, seaTemp=hymexSeaTemp, minR=hymexMinR,
        maxR=hymexMaxR, classCols=paste("class", seq(1,32), sep=""),
        stations=stations, timeRes=hymexTimeRes,
        pluvioStations=pluvioStations)

    iCol = paste("moment_", moment_i, sep="")
    jCol = paste("moment_", moment_j, sep="")
    rawDat[, (iCol) := dsdMoment(.SD, n=moment_i,
                        cols=paste("class", seq(1,32), sep=""))]
    rawDat[, (jCol) := dsdMoment(.SD, n=moment_j,
                        cols=paste("class", seq(1,32), sep=""))]

    rawDat = addRainStats(rawDat, timestepSeconds=hymexTimeRes,
        seaLevelTemperature=hymexSeaTemp, radar=FALSE, stations=stations)

    rawDSDs = rawDat[R >= hymexMinR,
        c("POSIXtime", "station", paste("class", seq(1,32), sep="")), with=FALSE]

    rawDat = rawDat[, c("POSIXtime", "station", iCol, jCol, "alt", "lat",
        "containedNonZeroStatus", "parsivelR", "solidPrecipProp"), with=FALSE]
    setnames(rawDat, "alt", "altitude")
    setnames(rawDat, "lat", "latitude")

    reconHymex = reconstructFromMoments(dat=rawDat, i=moment_i, j=moment_j,
        mu=gamma_mu, c=gamma_c, diams=D, widths=dD,
        seaLevelTemp=hymexSeaTemp, seaLevelHumidity=hymexHumidity,
        idcols=c("POSIXtime", "station", "containedNonZeroStatus",
            "parsivelR", "solidPrecipProp"))

    reconClasses = data.frame(min=as.numeric(D-dD/2),
        max=as.numeric(D+dD/2))

    reconComp = compareParsPluv(parsDat=reconHymex,
        pluvDat=pluvDat, seaTemp=hymexSeaTemp, minR=hymexMinR,
        maxR=hymexMaxR, classCols=paste("reconClass", seq(1,length(D)), sep=""),
        stations=stations, timeRes=hymexTimeRes,
        pluvioStations=pluvioStationsDefinition(),
        classes=reconClasses)

    return(list(raw=rawComp, corr=corrComp, recon=reconComp, rawDSDs=rawDSDs))
}

compareNumStations = function(reconStats=hymexComp_5min$recon$stats,
    rawStats=hymexComp_5min$raw$stats,
    corrStats=hymexComp_5min$corr$stats) {
    ## Do fast comparisons of the number of stations that were better 
    ## for each tested technique.
    ## 
    ## Args:
    ##   reconStats: Reconstructed statistics.
    ##   rawStats: Basic-filter statistics.
    ##   corrStats: DSD correction statistics.
    ##
    ## Statistics produced by processHyMeXComps().
    ## Returns: List containing the total number of stations, and the 
    ## number of times each technique beats the other techniques.
    
    setkey(reconStats, station)
    setkey(rawStats, station)
    setkey(corrStats, station)
    stopifnot(identical(reconStats[, station], corrStats[, station]))
    stopifnot(identical(reconStats[, station], rawStats[, station]))
    numStations = nrow(reconStats)

    ## Number of stations at which corrected beats raw.
    corrBeatsRaw = length(which(rawStats[, abs(medRB)] - corrStats[, abs(medRB)] >= 0))

    ## Number of stations at which reconstructed beats raw.
    reconBeatsRaw = length(which(rawStats[, abs(medRB)] - reconStats[, abs(medRB)] >= 0))

    ## Number of stations at which reconstructed beats corrected.
    reconBeatsCorr = length(which(corrStats[, abs(medRB)] - reconStats[, abs(medRB)] >= 0))

    ## Number of stations at which amount was better by recon than by DSD corrected.
    reconBeatsCorrAmount = length(which(corrStats[, abs(amountRelBias)] -
        reconStats[, abs(amountRelBias)] >= 0))

    list(total=numStations, corrBeatsRaw=corrBeatsRaw, reconBeatsRaw=reconBeatsRaw,
         reconBeatsCorr=reconBeatsCorr, reconBeatsCorrAmount=reconBeatsCorrAmount)
}
